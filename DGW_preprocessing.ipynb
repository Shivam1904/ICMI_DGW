{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import glob\n",
    "import math\n",
    "\n",
    "import cv2\n",
    "import dlib\n",
    "import numpy as np\n",
    "\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOURCE_PATH = \"dgw/input\"\n",
    "RESULT_PATH = \"dgw/preprocessed\"\n",
    "\n",
    "FACE_DETECTOR_MODEL = \"pre_trained_models/mmod_human_face_detector.dat\"\n",
    "PROCESSING_DEVICE = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomPoint:\n",
    "    def __init__(self, X, Y):\n",
    "        self.x = X\n",
    "        self.y = Y\n",
    "\n",
    "class CustomRectangle:\n",
    "    def __init__(self, topLeft, bottomRight):\n",
    "        self.topLeft = topLeft\n",
    "        self.bottomRight = bottomRight\n",
    "        \n",
    "        self.height = abs(topLeft.y - bottomRight.y)\n",
    "        self.width = abs(bottomRight.x - topLeft.x)\n",
    "    \n",
    "    def get_area(self):\n",
    "        area = self.height * self.width\n",
    "        return abs(area)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boundary_check(val, min_threshold=None, max_threshold=None):\n",
    "    if min_threshold is not None and val < min_threshold:\n",
    "        val = min_threshold\n",
    "    elif max_threshold is not None and val > max_threshold:\n",
    "        val = max_threshold\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_facial_landmarks(img):\n",
    "    import face_alignment\n",
    "    face_detector = face_alignment.FaceAlignment(\n",
    "        face_alignment.LandmarksType._2D,\n",
    "        flip_input=False,\n",
    "        device=PROCESSING_DEVICE\n",
    "    )\n",
    "\n",
    "    facial_landmarks = face_detector.get_landmarks(img)\n",
    "    return facial_landmarks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_driver_face(img):\n",
    "    upsample_num = 1\n",
    "\n",
    "    hog_face_detector = dlib.get_frontal_face_detector()\n",
    "    cnn_face_detector = dlib.cnn_face_detection_model_v1(FACE_DETECTOR_MODEL)\n",
    "    \n",
    "    detected_faces = hog_face_detector(img, 1)\n",
    "    is_using_cnn = False\n",
    "    if not detected_faces:\n",
    "        detected_faces = cnn_face_detector(img, upsample_num)\n",
    "        is_using_cnn = True\n",
    "\n",
    "    if not detected_faces:\n",
    "        raise Exception(\"No faces found.\")\n",
    "    \n",
    "    main_face = None\n",
    "    main_face_area = 0\n",
    "\n",
    "#     print(\"FACE DETECTED \", len(detected_faces))\n",
    "    for i in range(len(detected_faces)):\n",
    "        current_face = detected_faces[i]\n",
    "        if is_using_cnn:\n",
    "            current_face = detected_faces[i].rect\n",
    "        \n",
    "        top_left = CustomPoint(\n",
    "            boundary_check(current_face.left(), 0, img.shape[1]), \n",
    "            boundary_check(current_face.top(), 0, img.shape[0])\n",
    "        )\n",
    "        bottom_right = CustomPoint(\n",
    "            boundary_check(current_face.right(), 0, img.shape[1]), \n",
    "            boundary_check(current_face.bottom(), 0, img.shape[0])\n",
    "        )\n",
    "    \n",
    "        current_face_area = CustomRectangle(top_left, bottom_right).get_area()\n",
    "        \n",
    "        if current_face_area > main_face_area:\n",
    "            main_face = current_face\n",
    "            main_face_area = current_face_area\n",
    "\n",
    "    return img[\n",
    "        boundary_check(main_face.top(), 0, img.shape[0]):boundary_check(main_face.bottom(), 0, img.shape[1]), \n",
    "        boundary_check(main_face.left(), 0, img.shape[0]):boundary_check(main_face.right(), 0, img.shape[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_head_pose(img, landmarks):\n",
    "    size = img.shape\n",
    "\n",
    "    image_points = np.array([\n",
    "                            landmarks[33],     # Nose tip\n",
    "                            landmarks[8],      # Chin\n",
    "                            landmarks[36],     # Left eye left corner\n",
    "                            landmarks[45],     # Right eye right corne\n",
    "                            landmarks[48],     # Left Mouth corner\n",
    "                            landmarks[54]      # Right mouth corner\n",
    "                        ], dtype=float)\n",
    "                        \n",
    "    model_points = np.array([\n",
    "                            (0.0, 0.0, 0.0),             # Nose tip\n",
    "                            (0.0, -330.0, -65.0),        # Chin\n",
    "                            (-165.0, 170.0, -135.0),     # Left eye left corner\n",
    "                            (165.0, 170.0, -135.0),      # Right eye right corne\n",
    "                            (-150.0, -150.0, -125.0),    # Left Mouth corner\n",
    "                            (150.0, -150.0, -125.0)      # Right mouth corner                         \n",
    "                        ], dtype=float)\n",
    "\n",
    "    # Camera internals\n",
    "    center = (size[1]/2, size[0]/2)\n",
    "    focal_length = center[0] / np.tan(60/2 * np.pi / 180)\n",
    "    camera_matrix = np.array(\n",
    "                         [[focal_length, 0, center[0]],\n",
    "                         [0, focal_length, center[1]],\n",
    "                         [0, 0, 1]], dtype = float\n",
    "                         )\n",
    "\n",
    "    dist_coeffs = np.zeros((4,1)) # Assuming no lens distortion\n",
    "\n",
    "    (success, rotation_vector, translation_vector) = cv2.solvePnP(model_points, image_points, camera_matrix, dist_coeffs, flags=cv2.SOLVEPNP_ITERATIVE)\n",
    "\n",
    "    \n",
    "    axis = np.float32([[500,0,0], \n",
    "                          [0,500,0], \n",
    "                          [0,0,500]])\n",
    "                          \n",
    "    imgpts, jac = cv2.projectPoints(axis, rotation_vector, translation_vector, camera_matrix, dist_coeffs)\n",
    "    modelpts, jac2 = cv2.projectPoints(model_points, rotation_vector, translation_vector, camera_matrix, dist_coeffs)\n",
    "    rvec_matrix = cv2.Rodrigues(rotation_vector)[0]\n",
    "\n",
    "    proj_matrix = np.hstack((rvec_matrix, translation_vector))\n",
    "    eulerAngles = cv2.decomposeProjectionMatrix(proj_matrix)[6] \n",
    "\n",
    "    \n",
    "    pitch, yaw, roll = [math.radians(_) for _ in eulerAngles]\n",
    "\n",
    "\n",
    "    pitch = math.degrees(math.asin(math.sin(pitch)))\n",
    "    roll = -math.degrees(math.asin(math.sin(roll)))\n",
    "    yaw = math.degrees(math.asin(math.sin(yaw)))\n",
    "\n",
    "    return imgpts, modelpts, str(int(roll)), str(int(pitch)), str(int(yaw))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_extra_padding(landmarks):\n",
    "    return np.linalg.norm(landmarks[38] - landmarks[20])\n",
    "\n",
    "def get_driver_eyes(img, landmarks):\n",
    "    \n",
    "    FACIAL_LANDMARKS_IDXS = OrderedDict([\n",
    "        (\"mouth\", (48, 68)),\n",
    "        (\"right_eyebrow\", (17, 22)),\n",
    "        (\"left_eyebrow\", (22, 27)),\n",
    "        (\"right_eye\", (36, 42)),\n",
    "        (\"left_eye\", (42, 48)),\n",
    "        (\"nose\", (27, 35)),\n",
    "        (\"jaw\", (0, 17))\n",
    "    ])\n",
    "    \n",
    "    left_eye = landmarks[FACIAL_LANDMARKS_IDXS[\"left_eye\"][0]:FACIAL_LANDMARKS_IDXS[\"left_eye\"][1]]\n",
    "    right_eye = landmarks[FACIAL_LANDMARKS_IDXS[\"right_eye\"][0]:FACIAL_LANDMARKS_IDXS[\"right_eye\"][1]]\n",
    "    left_eyebrow = landmarks[FACIAL_LANDMARKS_IDXS[\"left_eyebrow\"][0]:FACIAL_LANDMARKS_IDXS[\"left_eyebrow\"][1]]\n",
    "    right_eyebrow = landmarks[FACIAL_LANDMARKS_IDXS[\"right_eyebrow\"][0]:FACIAL_LANDMARKS_IDXS[\"right_eyebrow\"][1]]\n",
    "    \n",
    "    \n",
    "    eyes = np.concatenate((left_eye, right_eye, left_eyebrow, right_eyebrow))\n",
    "    top_left_x = int(min(eyes, key = lambda t: t[0])[0] - get_extra_padding(landmarks))\n",
    "    top_left_y = int(min(eyes, key = lambda t: t[1])[1])\n",
    "    \n",
    "    bottom_right_x = int(max(eyes, key = lambda t: t[0])[0] + get_extra_padding(landmarks))\n",
    "    bottom_right_y = int(max(eyes, key = lambda t: t[1])[1] + get_extra_padding(landmarks))\n",
    "    \n",
    "#     print([\n",
    "#         boundary_check(top_left_x, 0, img.shape[0]), boundary_check(bottom_right_x, 0, img.shape[0]), \n",
    "#         boundary_check(top_left_y, 0, img.shape[1]), boundary_check(bottom_right_y, 0, img.shape[1])])\n",
    "\n",
    "    return img[\n",
    "        boundary_check(top_left_y, 0, img.shape[1]):boundary_check(bottom_right_y, 0, img.shape[1]),\n",
    "        boundary_check(top_left_x, 0, img.shape[0]):boundary_check(bottom_right_x, 0, img.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file_path in glob.glob(\"{src}/[0-9]/*.png\".format(src=SOURCE_PATH)):\n",
    "    path_info = file_path.split(\"/\")\n",
    "    IMAGE_NAME = path_info[-1].replace(\".png\", \"\")\n",
    "    ZONE_NAME = path_info[-2]\n",
    "    \n",
    "    img = dlib.load_rgb_image(file_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "   # Extract the face driver's face using dlib\n",
    "    try:\n",
    "        face_img = get_driver_face(img)\n",
    "    except Exception as e:\n",
    "        print(\"Unable to detect faces at {}\".format(file_path))\n",
    "    \n",
    "    # Extract 2D landmarks using face_alignment\n",
    "    try:\n",
    "        landmarks = get_facial_landmarks(face_img)\n",
    "    except Exception as e:\n",
    "        print(\"Unable to detect landmarks at {}\".format(file_path))\n",
    "    \n",
    "    # Extract driver eye's ROI\n",
    "    try:\n",
    "        eye_image = get_driver_eyes(face_img, landmarks)\n",
    "    except Exception as e:\n",
    "        print(\"Unable to get driver eye at {}\".format(file_path))\n",
    "    \n",
    "    # Extract head pose using solvePnP\n",
    "    try:\n",
    "        imgpts, _, roll, pitch, yaw = get_head_pose(face_img, landmarks)\n",
    "    except:\n",
    "        print(\"Unable to fetch head pose at {}\".format(file_path))\n",
    "    \n",
    "    \n",
    "    op_path_face_cropped = \"{dir}/{zone}/cropped_{img}.png\".format(dir=RESULT_PATH, zone=ZONE_NAME, img=IMAGE_NAME)\n",
    "    cv2.imwrite(op_path_face_cropped, face_img)\n",
    "\n",
    "    op_path_eye_cropped = \"{dir}/{zone}/eye_{img}.png\".format(dir=RESULT_PATH, zone=ZONE_NAME, img=IMAGE_NAME)\n",
    "    cv2.imwrite(op_path_eye_cropped, eye_image)\n",
    "\n",
    "#     # For testing the head pose     \n",
    "#     cv2.line(img, tuple(landmarks[33]), tuple(imgpts[1].ravel()), (0,255,0), 3) #GREEN\n",
    "#     cv2.line(img, tuple(landmarks[33]), tuple(imgpts[0].ravel()), (255,0,), 3) #BLUE\n",
    "#     cv2.line(img, tuple(landmarks[33]), tuple(imgpts[2].ravel()), (0,0,255), 3) #RED\n",
    "#     op_path_head_pose = \"{dir}/{zone}/headpose_{img}.png\".format(dir=RESULT_PATH, zone=ZONE_NAME, img=IMAGE_NAME)\n",
    "#     cv2.imwrite(op_path_head_pose, img)    \n",
    "    \n",
    "    feature_list = list()\n",
    "    # index 0: zone name\n",
    "    feature_list.append(ZONE_NAME)\n",
    "    # index 1: image name\n",
    "    feature_list.append(IMAGE_NAME)\n",
    "    \n",
    "    flat_landmarks = [item for sublist in landmarks for item in sublist]\n",
    "    # index 2-137: landmarks\n",
    "    feature_list.extend(flat_landmarks)\n",
    "    \n",
    "    # index 138-140: headpose\n",
    "    feature_list.extend([roll, pitch, yaw])\n",
    "    \n",
    "    # index 141: face_size\n",
    "    feature_list.append(face_img.shape[0])\n",
    "    \n",
    "    if (len(feature_list) != 142):\n",
    "        print(\"Unable to fetch all the features for image {} in zone {}.\".format(\n",
    "            IMAGE_NAME, ZONE_NAME))\n",
    "    else:\n",
    "        feature_file = \"{dir}/{zone}/feature.csv\".format(dir=RESULT_PATH, zone=ZONE_NAME)\n",
    "        with open(feature_file, 'a+', newline='') as csvfile:\n",
    "            spamwriter = csv.writer(csvfile, delimiter=' ')\n",
    "            spamwriter.writerow(feature_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
