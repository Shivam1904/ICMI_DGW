{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tqdm'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-17c4fc44a066>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdlib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tqdm'"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "import glob\n",
    "import cv2\n",
    "import dlib\n",
    "import numpy as np\n",
    "\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOURCE_PATH = \"dgw/input\"\n",
    "RESULT_PATH = \"dgw/preprocessed\"\n",
    "\n",
    "FACE_DETECTOR_MODEL = \"pre_trained_models/mmod_human_face_detector.dat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_facial_landmarks(img):\n",
    "    import face_alignment\n",
    "    \n",
    "    face_detector = face_alignment.FaceAlignment(\n",
    "        face_alignment.LandmarksType._2D,\n",
    "        flip_input=False,\n",
    "        device='cpu'\n",
    "    )\n",
    "\n",
    "    facial_landmarks = face_detector.get_landmarks(img)\n",
    "    \n",
    "    return facial_landmarks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Point:\n",
    "    def __init__(self, X, Y):\n",
    "        self.x = X\n",
    "        self.y = Y\n",
    "\n",
    "class C_Rectangle:\n",
    "    def __init__(self, topLeft, bottomRight):\n",
    "        self.topLeft = topLeft\n",
    "        self.bottomRight = bottomRight\n",
    "        \n",
    "        self.height = topLeft.y - bottomRight.y\n",
    "        self.width = bottomRight.x - topLeft.x\n",
    "    \n",
    "    def get_area(self):\n",
    "        area = self.height * self.width\n",
    "        return area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_driver_face(img):\n",
    "    upsample_num = 1\n",
    "\n",
    "    hog_face_detector = dlib.get_frontal_face_detector()\n",
    "    cnn_face_detector = dlib.cnn_face_detection_model_v1(FACE_DETECTOR_MODEL)\n",
    "    \n",
    "    detected_faces = hog_face_detector(img, 1)\n",
    "    is_using_cnn = False\n",
    "    if not detected_faces:\n",
    "        detected_faces = cnn_face_detector(img, upsample_num)\n",
    "        is_using_cnn = True\n",
    "\n",
    "    if not detected_faces:\n",
    "        print(\"Unable to detect any faces at {}\".format(\"ABC\"))\n",
    "    \n",
    "    main_face = None\n",
    "    main_face_area = 0\n",
    "    for i in range(len(detected_faces)):\n",
    "        current_face = detected_faces[i]\n",
    "        if is_using_cnn:\n",
    "            current_face = detected_faces[i].rect\n",
    "        \n",
    "        top_left = Point(current_face.left(), current_face.top())\n",
    "        bottom_right = Point(current_face.right(), current_face.bottom())\n",
    "    \n",
    "        current_face_area = C_Rectangle(top_left, bottom_right).get_area()\n",
    "        if not main_face or current_face_area > main_face_area:\n",
    "            main_face = current_face\n",
    "            main_face_area = current_face_area\n",
    "\n",
    "    return img[main_face.top():main_face.bottom(), main_face.left():main_face.right()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_driver_eyes(landmarks):\n",
    "    \n",
    "    FACIAL_LANDMARKS_IDXS = OrderedDict([\n",
    "        (\"mouth\", (48, 68)),\n",
    "        (\"right_eyebrow\", (17, 22)),\n",
    "        (\"left_eyebrow\", (22, 27)),\n",
    "        (\"right_eye\", (36, 42)),\n",
    "        (\"left_eye\", (42, 48)),\n",
    "        (\"nose\", (27, 35)),\n",
    "        (\"jaw\", (0, 17))\n",
    "    ])\n",
    "    \n",
    "    left_eye = landmarks[FACIAL_LANDMARKS_IDXS[\"left_eye\"][0]:FACIAL_LANDMARKS_IDXS[\"left_eye\"][1]]\n",
    "    right_eye = landmarks[FACIAL_LANDMARKS_IDXS[\"right_eye\"][0]:FACIAL_LANDMARKS_IDXS[\"right_eye\"][1]]\n",
    "    \n",
    "    eyes = np.concatenate((left_eye, right_eye))\n",
    "    top_left_x = min(eyes, key = lambda t: t[0])[0]\n",
    "    top_left_y = min(eyes, key = lambda t: t[1])[1]\n",
    "    \n",
    "    bottom_right_x = max(eyes, key = lambda t: t[0])[0]\n",
    "    bottom_right_y = max(eyes, key = lambda t: t[1])[1]\n",
    "    \n",
    "    return ((top_left_x, top_left_y), (bottom_right_x, bottom_right_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file_path in glob.glob(\"{src}/[0-9]/*.png\".format(src=SOURCE_PATH)):\n",
    "    path_info = file_path.split(\"/\")\n",
    "    IMAGE_NAME = path_info[-1].replace(\".png\", \"\")\n",
    "    ZONE_NAME = path_info[-2]\n",
    "    \n",
    "    img = dlib.load_rgb_image(file_path)\n",
    "    \n",
    "    face_img = get_driver_face(img)\n",
    "    op_path = \"{dir}/{zone}/cropped_{img}.png\".format(dir=RESULT_PATH, zone=ZONE_NAME, img=IMAGE_NAME)\n",
    "#     print(op_path)\n",
    "    cv2.imwrite(op_path, face_img)\n",
    "\n",
    "    landmarks = get_facial_landmarks(face_img)    \n",
    "#     for i in range(len(landmarks[0])):\n",
    "#         print(i, landmarks[0][i])\n",
    "\n",
    "    eyes_boundng_box = get_driver_eyes(landmarks[0])\n",
    "    eye_image = cv2.rectangle(face_img, eyes_boundng_box[0], eyes_boundng_box[1], (255, 0, 0) , 2) \n",
    "    op_path = \"{dir}/{zone}/eye_{img}.png\".format(dir=RESULT_PATH, zone=ZONE_NAME, img=IMAGE_NAME)\n",
    "    print(op_path)\n",
    "    cv2.imwrite(op_path, eye_image)\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "icmi_env",
   "language": "python",
   "name": "icmi_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
