{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import glob\n",
    "import cv2\n",
    "import dlib\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOURCE_PATH = \"dgw/input\"\n",
    "RESULT_PATH = \"dgw/preprocessed\"\n",
    "\n",
    "FACE_DETECTOR_MODEL = \"pre_trained_models/mmod_human_face_detector.dat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Point:\n",
    "    def __init__(self, X, Y):\n",
    "        self.x = X\n",
    "        self.y = Y\n",
    "\n",
    "class C_Rectangle:\n",
    "    def __init__(self, topLeft, bottomRight):\n",
    "        self.topLeft = topLeft\n",
    "        self.bottomRight = bottomRight\n",
    "        \n",
    "        self.height = topLeft.y - bottomRight.y\n",
    "        self.width = bottomRight.x - topLeft.x\n",
    "    \n",
    "    def get_area(self):\n",
    "        area = self.height * self.width\n",
    "        return abs(area)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boundary_check(val, min_threshold=None, max_threshold=None):\n",
    "    if min_threshold is not None and val < min_threshold:\n",
    "        val = min_threshold\n",
    "    elif max_threshold is not None and val > max_threshold:\n",
    "        val = max_threshold\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_facial_landmarks(img):\n",
    "    import face_alignment\n",
    "    \n",
    "    face_detector = face_alignment.FaceAlignment(\n",
    "        face_alignment.LandmarksType._2D,\n",
    "        flip_input=False,\n",
    "        device='cpu'\n",
    "    )\n",
    "\n",
    "    facial_landmarks = face_detector.get_landmarks(img)\n",
    "    \n",
    "    return facial_landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_driver_face(img):\n",
    "    upsample_num = 1\n",
    "\n",
    "    hog_face_detector = dlib.get_frontal_face_detector()\n",
    "    cnn_face_detector = dlib.cnn_face_detection_model_v1(FACE_DETECTOR_MODEL)\n",
    "    \n",
    "    detected_faces = hog_face_detector(img, 1)\n",
    "    is_using_cnn = False\n",
    "    if not detected_faces:\n",
    "        detected_faces = cnn_face_detector(img, upsample_num)\n",
    "        is_using_cnn = True\n",
    "\n",
    "    if not detected_faces:\n",
    "        print(\"Unable to detect any faces at {}\".format(\"ABC\"))\n",
    "    \n",
    "    main_face = None\n",
    "    main_face_area = 0\n",
    "    for i in range(len(detected_faces)):\n",
    "        current_face = detected_faces[i]\n",
    "        if is_using_cnn:\n",
    "            current_face = detected_faces[i].rect\n",
    "        \n",
    "        top_left = Point(\n",
    "            boundary_check(current_face.left(), 0, img.shape[1]), \n",
    "            boundary_check(current_face.top(), 0, img.shape[0])\n",
    "        )\n",
    "        bottom_right = Point(\n",
    "            boundary_check(current_face.right(), 0, img.shape[1]), \n",
    "            boundary_check(current_face.bottom(), 0, img.shape[0])\n",
    "        )\n",
    "    \n",
    "        current_face_area = C_Rectangle(top_left, bottom_right).get_area()\n",
    "        if not main_face or current_face_area > main_face_area:\n",
    "            main_face = current_face\n",
    "            main_face_area = current_face_area\n",
    "\n",
    "    return img[\n",
    "        boundary_check(current_face.top(), 0, img.shape[0]):boundary_check(current_face.bottom(), 0, img.shape[1]), \n",
    "        boundary_check(current_face.left(), 0, img.shape[0]):boundary_check(current_face.right(), 0, img.shape[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def face_orientation(frame, landmarks):\n",
    "    size = frame.shape #(height, width, color_channel)\n",
    "\n",
    "    image_points = np.array([\n",
    "                            landmarks[33],     # Nose tip\n",
    "                            landmarks[8],      # Chin\n",
    "                            landmarks[36],     # Left eye left corner\n",
    "                            landmarks[45],     # Right eye right corne\n",
    "                            landmarks[48],     # Left Mouth corner\n",
    "                            landmarks[54]      # Right mouth corner\n",
    "                        ], dtype=float)\n",
    "                        \n",
    "    model_points = np.array([\n",
    "                            (0.0, 0.0, 0.0),             # Nose tip\n",
    "                            (0.0, -330.0, -65.0),        # Chin\n",
    "                            (-165.0, 170.0, -135.0),     # Left eye left corner\n",
    "                            (165.0, 170.0, -135.0),      # Right eye right corne\n",
    "                            (-150.0, -150.0, -125.0),    # Left Mouth corner\n",
    "                            (150.0, -150.0, -125.0)      # Right mouth corner                         \n",
    "                        ], dtype=float)\n",
    "\n",
    "    # Camera internals\n",
    "    center = (size[1]/2, size[0]/2)\n",
    "    focal_length = center[0] / np.tan(60/2 * np.pi / 180)\n",
    "    camera_matrix = np.array(\n",
    "                         [[focal_length, 0, center[0]],\n",
    "                         [0, focal_length, center[1]],\n",
    "                         [0, 0, 1]], dtype = float\n",
    "                         )\n",
    "\n",
    "    dist_coeffs = np.zeros((4,1)) # Assuming no lens distortion\n",
    "\n",
    "    (success, rotation_vector, translation_vector) = cv2.solvePnP(model_points, image_points, camera_matrix, dist_coeffs, flags=cv2.SOLVEPNP_ITERATIVE)\n",
    "\n",
    "    \n",
    "    axis = np.float32([[500,0,0], \n",
    "                          [0,500,0], \n",
    "                          [0,0,500]])\n",
    "                          \n",
    "    imgpts, jac = cv2.projectPoints(axis, rotation_vector, translation_vector, camera_matrix, dist_coeffs)\n",
    "    modelpts, jac2 = cv2.projectPoints(model_points, rotation_vector, translation_vector, camera_matrix, dist_coeffs)\n",
    "    rvec_matrix = cv2.Rodrigues(rotation_vector)[0]\n",
    "\n",
    "    proj_matrix = np.hstack((rvec_matrix, translation_vector))\n",
    "    eulerAngles = cv2.decomposeProjectionMatrix(proj_matrix)[6] \n",
    "\n",
    "    \n",
    "    pitch, yaw, roll = [math.radians(_) for _ in eulerAngles]\n",
    "\n",
    "\n",
    "    pitch = math.degrees(math.asin(math.sin(pitch)))\n",
    "    roll = -math.degrees(math.asin(math.sin(roll)))\n",
    "    yaw = math.degrees(math.asin(math.sin(yaw)))\n",
    "\n",
    "    return imgpts, modelpts, str(int(roll)), str(int(pitch)), str(int(yaw))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_extra_padding(landmarks):\n",
    "    return np.linalg.norm(landmarks[38] - landmarks[20])\n",
    "\n",
    "def get_driver_eyes(landmarks):\n",
    "    \n",
    "    FACIAL_LANDMARKS_IDXS = OrderedDict([\n",
    "        (\"mouth\", (48, 68)),\n",
    "        (\"right_eyebrow\", (17, 22)),\n",
    "        (\"left_eyebrow\", (22, 27)),\n",
    "        (\"right_eye\", (36, 42)),\n",
    "        (\"left_eye\", (42, 48)),\n",
    "        (\"nose\", (27, 35)),\n",
    "        (\"jaw\", (0, 17))\n",
    "    ])\n",
    "    \n",
    "    left_eye = landmarks[FACIAL_LANDMARKS_IDXS[\"left_eye\"][0]:FACIAL_LANDMARKS_IDXS[\"left_eye\"][1]]\n",
    "    right_eye = landmarks[FACIAL_LANDMARKS_IDXS[\"right_eye\"][0]:FACIAL_LANDMARKS_IDXS[\"right_eye\"][1]]\n",
    "    left_eyebrow = landmarks[FACIAL_LANDMARKS_IDXS[\"left_eyebrow\"][0]:FACIAL_LANDMARKS_IDXS[\"left_eyebrow\"][1]]\n",
    "    right_eyebrow = landmarks[FACIAL_LANDMARKS_IDXS[\"right_eyebrow\"][0]:FACIAL_LANDMARKS_IDXS[\"right_eyebrow\"][1]]\n",
    "\n",
    "    eyes = np.concatenate((left_eye, right_eye, left_eyebrow, right_eyebrow))\n",
    "    top_left_x = min(eyes, key = lambda t: t[0])[0] - get_extra_padding(landmarks)\n",
    "    top_left_y = min(eyes, key = lambda t: t[1])[1]\n",
    "    \n",
    "    bottom_right_x = max(eyes, key = lambda t: t[0])[0] + get_extra_padding(landmarks)\n",
    "    bottom_right_y = max(eyes, key = lambda t: t[1])[1] + get_extra_padding(landmarks)\n",
    "    \n",
    "    return ((top_left_x, top_left_y), (bottom_right_x, bottom_right_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----\n",
      "346 190\n",
      "698 542\n",
      "-----\n",
      "dgw/preprocessed/1/cropped_fresh.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-15-f090c299afe2>:20: DeprecationWarning: an integer is required (got type numpy.float32).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  eye_image = cv2.rectangle(face_img, eyes_boundng_box[0], eyes_boundng_box[1], (255, 0, 0) , 2)\n",
      "<ipython-input-15-f090c299afe2>:27: DeprecationWarning: an integer is required (got type numpy.float32).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  cv2.line(face_img, tuple(landmarks[0][33]), tuple(imgpts[1].ravel()), (0,255,0), 3) #GREEN\n",
      "<ipython-input-15-f090c299afe2>:28: DeprecationWarning: an integer is required (got type numpy.float32).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  cv2.line(face_img, tuple(landmarks[0][33]), tuple(imgpts[0].ravel()), (255,0,), 3) #BLUE\n",
      "<ipython-input-15-f090c299afe2>:29: DeprecationWarning: an integer is required (got type numpy.float32).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  cv2.line(face_img, tuple(landmarks[0][33]), tuple(imgpts[2].ravel()), (0,0,255), 3) #RED\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dgw/preprocessed/1/eye_fresh.png\n",
      "-63 39 -71\n",
      "-----\n",
      "47 244\n",
      "251 447\n",
      "-----\n",
      "dgw/preprocessed/1/cropped_c.png\n",
      "dgw/preprocessed/1/eye_c.png\n",
      "-7 -4 70\n",
      "-----\n",
      "111 82\n",
      "379 350\n",
      "-----\n",
      "dgw/preprocessed/1/cropped_1.png\n",
      "dgw/preprocessed/1/eye_1.png\n",
      "0 -16 1\n",
      "-----\n",
      "390 184\n",
      "545 339\n",
      "-----\n",
      "dgw/preprocessed/3/cropped_frame257.png\n",
      "dgw/preprocessed/3/eye_frame257.png\n",
      "-2 -19 -3\n",
      "-----\n",
      "159 0\n",
      "345 180\n",
      "-----\n",
      "dgw/preprocessed/3/cropped_fresh.png\n",
      "dgw/preprocessed/3/eye_fresh.png\n",
      "-5 -6 -34\n",
      "-----\n",
      "111 82\n",
      "379 350\n",
      "-----\n",
      "dgw/preprocessed/3/cropped_3.png\n",
      "dgw/preprocessed/3/eye_3.png\n",
      "0 -16 1\n",
      "-----\n",
      "45 10\n",
      "81 46\n",
      "-----\n",
      "-----\n",
      "161 42\n",
      "197 78\n",
      "-----\n",
      "dgw/preprocessed/2/cropped_d.png\n",
      "dgw/preprocessed/2/eye_d.png\n",
      "5 -15 -34\n",
      "-----\n",
      "111 82\n",
      "379 350\n",
      "-----\n",
      "dgw/preprocessed/2/cropped_2.png\n",
      "dgw/preprocessed/2/eye_2.png\n",
      "0 -16 1\n"
     ]
    }
   ],
   "source": [
    "for file_path in glob.glob(\"{src}/[0-9]/*.png\".format(src=SOURCE_PATH)):\n",
    "    path_info = file_path.split(\"/\")\n",
    "    IMAGE_NAME = path_info[-1].replace(\".png\", \"\")\n",
    "    ZONE_NAME = path_info[-2]\n",
    "    \n",
    "    img = dlib.load_rgb_image(file_path)\n",
    "#     img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    face_img = get_driver_face(img)\n",
    "    op_path = \"{dir}/{zone}/cropped_{img}.png\".format(dir=RESULT_PATH, zone=ZONE_NAME, img=IMAGE_NAME)\n",
    "    print(op_path)\n",
    "\n",
    "    cv2.imwrite(op_path, face_img)\n",
    "\n",
    "    landmarks = get_facial_landmarks(face_img)    \n",
    "#     for i in range(len(landmarks[0])):\n",
    "#         print(i, landmarks[0][i])\n",
    "\n",
    "    eyes_boundng_box = get_driver_eyes(landmarks[0])\n",
    "    eye_image = cv2.rectangle(face_img, eyes_boundng_box[0], eyes_boundng_box[1], (255, 0, 0) , 2) \n",
    "    op_path = \"{dir}/{zone}/eye_{img}.png\".format(dir=RESULT_PATH, zone=ZONE_NAME, img=IMAGE_NAME)\n",
    "    print(op_path)\n",
    "    cv2.imwrite(op_path, eye_image)\n",
    "    \n",
    "\n",
    "    imgpts, modelpts, roll, pitch, yaw = face_orientation(face_img, landmarks[0])\n",
    "    cv2.line(face_img, tuple(landmarks[0][33]), tuple(imgpts[1].ravel()), (0,255,0), 3) #GREEN\n",
    "    cv2.line(face_img, tuple(landmarks[0][33]), tuple(imgpts[0].ravel()), (255,0,), 3) #BLUE\n",
    "    cv2.line(face_img, tuple(landmarks[0][33]), tuple(imgpts[2].ravel()), (0,0,255), 3) #RED\n",
    "    op_path = \"{dir}/{zone}/headpose_{img}.png\".format(dir=RESULT_PATH, zone=ZONE_NAME, img=IMAGE_NAME)\n",
    "    cv2.imwrite(op_path, face_img)\n",
    "    print(roll, pitch, yaw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
